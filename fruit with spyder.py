from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pylab as plt

X = [\
[192.0, 8.4, 7.3, 0.55], \
[180.0, 8.0, 6.8, 0.59], \
[176.0, 7.4, 7.2, 0.6], \
[178.0, 7.1, 7.8, 0.92], \
[172.0, 7.4, 7.0, 0.89], \
[166.0, 6.9, 7.3, 0.93], \
[172.0, 7.1, 7.6, 0.92], \
[154.0, 7.0, 7.1, 0.88], \
[164.0, 7.3, 7.7, 0.7], \
[152.0, 7.6, 7.3, 0.69], \
[156.0, 7.7, 7.1, 0.69], \
[156.0, 7.6, 7.5, 0.67], \
[168.0, 7.5, 7.6, 0.73], \
[162.0, 7.5, 7.1, 0.83], \
[162.0, 7.4, 7.2, 0.85], \
[160.0, 7.5, 7.5, 0.86], \
[156.0, 7.4, 7.4, 0.84], \
[140.0, 7.3, 7.1, 0.87], \
[170.0, 7.6, 7.9, 0.88], \
[86.0, 6.2, 4.7, 0.8], \
[84.0, 6.0, 4.6, 0.79], \
[80.0, 5.8, 4.3, 0.77], \
[80.0, 5.9, 4.3, 0.81], \
[76.0, 5.8, 4.0, 0.81], \
[342.0, 9.0, 9.4, 0.75], \
[356.0, 9.2, 9.2, 0.75], \
[362.0, 9.6, 9.2, 0.74], \
[204.0, 7.5, 9.2, 0.77], \
[140.0, 6.7, 7.1, 0.72], \
[160.0, 7.0, 7.4, 0.81], \
[158.0, 7.1, 7.5, 0.79], \
[210.0, 7.8, 8.0, 0.82], \
[164.0, 7.2, 7.0, 0.8], \
[190.0, 7.5, 8.1, 0.74], \
[142.0, 7.6, 7.8, 0.75], \
[150.0, 7.1, 7.9, 0.75], \
[160.0, 7.1, 7.6, 0.76], \
[154.0, 7.3, 7.3, 0.79], \
[158.0, 7.2, 7.8, 0.77], \
[144.0, 6.8, 7.4, 0.75], \
[154.0, 7.1, 7.5, 0.78], \
[180.0, 7.6, 8.2, 0.79], \
[154.0, 7.2, 7.2, 0.82], \
[194.0, 7.2, 10.3, 0.7], \
[200.0, 7.3, 10.5, 0.72], \
[186.0, 7.2, 9.2, 0.72], \
[216.0, 7.3, 10.2, 0.71], \
[196.0, 7.3, 9.7, 0.72], \
[132.0, 5.8, 8.7, 0.73], \
[130.0, 6.0, 8.2, 0.71], \
[116.0, 6.0, 7.5, 0.72], \
[118.0, 5.9, 8.0, 0.72], \
[120.0, 6.0, 8.4, 0.74], \
[116.0, 6.1, 8.5, 0.71], \
[116.0, 6.3, 7.7, 0.72], \
[116.0, 5.9, 8.1, 0.73], \
[152.0, 6.5, 8.5, 0.72], \
[118.0, 6.1, 8.1, 0.7], \
]

Y = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]


def knn_learn(ts, k):
    
    global X, Y
    
    X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, test_size = ts)
    
    knn = KNeighborsClassifier(n_neighbors = int(k))
    knn.fit(X_Train, Y_Train)
    Y_Predict = knn.predict(X_Test)
    
    plt.plot(Y_Test, Y_Predict, ".")
    plt.show()
    return accuracy_score(Y_Test, Y_Predict)

def knn_result(exp, ts, k, learn):
    print("--------------------------------------------------------------")
    print("다음은", '"' + experiment + '"' + "입니다.")
    print("k = %d, test_data = %.2f%% 일때, 모델의 정확도는 %.2f%% 입니다." \
          % (k, 100 * ts, 100 * learn))
    print("--------------------------------------------------------------")
    
experiment = input("학습주제명 : ")
test_time = int(input("실험할 횟수 : "))
ts = float(input("test_data의 비율 : "))

for _ in range(test_time):
    k = int(input("k를 입력하세요 : "))
    knn_result(experiment, ts, k, knn_learn(ts, k))